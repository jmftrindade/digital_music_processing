{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21M.387 Fundamentals of Music Processing\n",
    "## Audio Retrieval\n",
    "\n",
    "In this unit, we look at two techniques for audio search: Audio Identification (aka fingerprints), and Audio Matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from ipywidgets import interact\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import fmplib as fmp\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 4)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "fmp.documentation_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Chapter 7.0 – 7.1 (pp 355 – 370)\n",
    "\n",
    "<img src=\"images/book_cover.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-Based Retrieval\n",
    "\n",
    "- Text search\n",
    "  - \"Beethoven\"\n",
    "  - \"Day Tripper\"\n",
    "- Metadata tags\n",
    "  - Often manually entered, or crowd-sourced\n",
    "  - Mood, tempo, genre\n",
    "\n",
    "<img src=\"images/text_based.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Content-Based Retrieval\n",
    "- Or \"query by example\"\n",
    "- Use raw musical data\n",
    "- Automatically return a list of items most similar to the query.\n",
    "\n",
    "<img src=\"images/content_based.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Types of Audio Retrieval Problems\n",
    "\n",
    "These are ordered by _specificity_ - most specific to least specific:\n",
    "- Audio Identification\n",
    "- Audio Matching\n",
    "- Version Identification\n",
    "- Category Based Retrieval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Audio Identification\n",
    "AKA - Audio Fingerprinting\n",
    "\n",
    "<img src=\"images/shazam.png\" width=300>\n",
    "\n",
    "Paper by Avery Wang (ISMIR 2003)\n",
    "\n",
    "### Goal\n",
    "Given:\n",
    "- A huge database of audio recordings \n",
    "- A _short audio fragment_, \n",
    "\n",
    "Identify the _original audio recording_ of the fragment... quickly.\n",
    "\n",
    "### System Overview\n",
    "<img src=\"images/audio_id_overview.png\" width=400>\n",
    "\n",
    "### Audio Fingerprint Properties\n",
    "- High Specificity - Discriminative \n",
    "- Highly Robust - Invariant to distortions\n",
    "- Compact\n",
    "- Scalable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Constellation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd = fmp.load_wav(\"audio/superstition_orig.wav\")\n",
    "fs = 22050.\n",
    "ipd.Audio(snd, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the spectrogram:\n",
    "- $N = 2048$\n",
    "- $H = 256$ (note smaller than \"normal\" hop size)\n",
    "- Look at low frequency ranges (more stable) from $0Hz - 4000Hz$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_len = 2048\n",
    "hop_size = 256\n",
    "max_bin = int(round(4000. * fft_len / fs))\n",
    "\n",
    "spec = fmp.stft_mag(snd, fft_len, hop_size)[0:max_bin,:]\n",
    "fmp.plot_spectrogram(spec, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find points of local maxima in a rectangular region: \"2D peak picking\"\n",
    "\n",
    "<img src=\"images/spec_local_max.png\" width=200>\n",
    "\n",
    "<font color=red>__Whiteboard__</font>: Local maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example, with:\n",
    "- $2 \\tau = 60 $ samples or $.7$ seconds\n",
    "- $2 \\kappa = 40 $ bins or $430$ Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 60\n",
    "height = 40\n",
    "points = fmp.make_constellation(snd, fft_len, hop_size, max_bin, width, height)\n",
    "\n",
    "def show_spec_and_points(spec, points, show_spec=True):\n",
    "    if show_spec:\n",
    "        fmp.plot_spectrogram(spec, cmap='Greys', colorbar=False)\n",
    "    plt.plot(points[:,0], points[:,1], 'ro')\n",
    "    plt.xlim(0, spec.shape[1])\n",
    "    plt.ylim(0, spec.shape[0])\n",
    "\n",
    "plt.figure()\n",
    "show_spec_and_points(spec, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(filt_sz=(2,14))\n",
    "def show_points(filt_sz):\n",
    "    filt = np.array((6,4)) * filt_sz\n",
    "    points = fmp.make_constellation(snd, fft_len, hop_size, max_bin, filt[0], filt[1])\n",
    "\n",
    "    txt = f'Time span: {filt[0]*hop_size/fs:.2f} sec ({filt[0]} samples)\\n'\n",
    "    txt += f'Freq span: {filt[1]*fs/fft_len:.0f} Hz ({filt[1]} bin)\\n'\n",
    "    txt += f'Num peaks: {points.shape[0]}'\n",
    "    plt.figure()\n",
    "    show_spec_and_points(spec, points)\n",
    "    plt.text(600, 450, txt, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness\n",
    "\n",
    "Original audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\"audio/superstition_orig.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Equalization__ (i.e., bad speaker or telephone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\"audio/superstition_eq.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Noise__ (loud location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\"audio/superstition_noise.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reverb__ (speakers in large space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\"audio/superstition_reverb.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(v=(1,3), orig=False)\n",
    "def show_points(v=1, orig=False):\n",
    "    if orig:\n",
    "        v = 0\n",
    "    version = (\"orig\", \"eq\", \"noise\", \"reverb\")[v]\n",
    "    snd = fmp.load_wav(\"audio/superstition_%s.wav\" % version)\n",
    "    spec = fmp.stft_mag(snd, fft_len, hop_size)[0:max_bin,:]\n",
    "    points = fmp.make_constellation(snd, fft_len, hop_size, max_bin)\n",
    "    plt.figure()\n",
    "    show_spec_and_points(spec, points)\n",
    "    plt.title(version, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about playing the song slower or faster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching\n",
    "\n",
    "Back to our peaks... or \"Constellation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = fmp.make_constellation(snd, fft_len, hop_size, max_bin) \n",
    "\n",
    "@interact(show_spec=True)\n",
    "def show_points(show_spec):\n",
    "    plt.figure()\n",
    "    show_spec_and_points(spec, points, show_spec)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concatenation of many songs $\\rightarrow$ Database\n",
    "- We call the database $\\mathcal{D}$ and the constellation map $\\mathcal{C(D)}$\n",
    "\n",
    "<font color=red>__Whiteboard__</font>: Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A query is a small fragment of audio recording. For example:  \n",
    "This is a 1.5 second \"time slice\" of the above audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = fmp.make_constellation(snd, fft_len, hop_size, max_bin)\n",
    "query = fmp.constellation_slice(points, 300, 429)\n",
    "\n",
    "plt.figure(figsize=(2, 4))\n",
    "plt.plot(query[:,0], query[:,1], 'bo');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This small bit of audio is the query $\\mathcal{Q}$ \n",
    "- The constellation map of the query is $\\mathcal{C(Q)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: To find the location of the query fragment in the constellation.\n",
    "\n",
    "Process:\n",
    "- shift $\\mathcal{C(Q)}$ along time axis of $\\mathcal{C(D)}$\n",
    "- count matching points at each time offset $\\rightarrow$ score\n",
    "- highest scoring shift amount is query match location\n",
    "\n",
    "Formally:\n",
    "$$\\Delta_{\\mathcal{C}}[m] = [m + \\mathcal{C(Q)}] \\cap \\mathcal{C(D)} $$\n",
    "\n",
    "where $m + \\mathcal{C(Q)}$ is a shift of all points in $\\mathcal{C(Q)}$ by $m$ time steps.\n",
    "\n",
    "The best shift (and match location) is:\n",
    "$$m = \\mathrm{argmax} \\Delta_{\\mathcal{C}}[m]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(pos=(0,800, 25))\n",
    "def slide_demo(pos=0):    \n",
    "    shifted = query[:,0] + pos\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.gcf().add_axes((0,.35,1,.5))\n",
    "    show_spec_and_points(spec, points, False)\n",
    "    plt.plot(shifted, query[:,1], 'bo')\n",
    "    plt.gcf().add_axes((0,0,1,.25))\n",
    "    match_score = fmp.slide_match(points, query)\n",
    "    match_score[pos+1:] = 0\n",
    "    plt.plot(match_score)\n",
    "    plt.xlim(0, spec.shape[1])\n",
    "    plt.ylim(0, 25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of \"altered query\" against database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(v=(0,3), show_q=True)\n",
    "def show_points(v=0, show_q=True):\n",
    "    # create alternate queries\n",
    "    version = (\"orig\", \"eq\", \"noise\", \"reverb\")[v]\n",
    "    snd = fmp.load_wav(\"audio/superstition_%s.wav\" % version)\n",
    "    spec = fmp.stft_mag(snd, fft_len, hop_size)[0:max_bin,:]\n",
    "    alt_pts = fmp.make_constellation(snd, fft_len, hop_size, max_bin)\n",
    "    query = fmp.constellation_slice(alt_pts, 300, 429)\n",
    "    \n",
    "    match_score = fmp.slide_match(points, query)\n",
    "    shifted = query[:,0] + np.argmax(match_score)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.gcf().add_axes((0,.35,1,.5))\n",
    "    show_spec_and_points(spec, points, False)\n",
    "    plt.title(version, fontsize=20)\n",
    "    if show_q:\n",
    "        plt.plot(shifted, query[:,1], 'bo')\n",
    "\n",
    "    plt.gcf().add_axes((0,0,1,.25))\n",
    "    plt.plot(match_score)\n",
    "    plt.xlim(0, spec.shape[1])\n",
    "    plt.ylim(0, 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To match a query against many songs:\n",
    "- Database is a concatenation of many song constellations.\n",
    "- Keep track of _time-offset_ per song in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Optimization\n",
    "\n",
    "<font color=red>__Whiteboard__</font>: Inverted lists\n",
    "\n",
    "- Compute a hash value $h$ for each constellation point $(n,k)$.\n",
    "  - Finite set of $h \\in \\mathcal{H}$\n",
    "  - Usually $h$ is a fixed-length binary number.\n",
    "- Create an set of __inverted lists__ $L(h) = \\lbrace l_1, l_2, \\dots \\rbrace$ for each $h$\n",
    "  - $l$ is the timestamp of the point $(n,k)$. i.e., $l=n$.\n",
    "\n",
    "Database example:\n",
    "\n",
    "<img src=\"images/hash_database.png\" width=400>\n",
    "\n",
    "Query example:\n",
    "\n",
    "<img src=\"images/hash_query.png\" width=130>\n",
    "\n",
    "- Queries are small (compared to Database).\n",
    "  - small # of points\n",
    "  - small subset of $\\mathcal{H}$\n",
    "\n",
    "To find the optimal query match (i.e. the shift amount):\n",
    "- for each query point $(n,h)$:\n",
    "  - compute $m = l - n$ for each $l \\in L(h)$ of the database.\n",
    "- most occuring $m$ is the optimal shift amount and therefore, the match location.\n",
    "\n",
    "<img src=\"images/hash_search.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial implementation\n",
    "For a first implementation, use a really simple hash function: $h = k$.  \n",
    "So $\\mathcal{H} = [0:K-1]$ - one value per frequency bin.\n",
    "\n",
    "Optimization savings:\n",
    "- $N$: database items (very large)\n",
    "- $M$: query items (small)\n",
    "- $L$: number of hash values $\\vert \\mathcal{H} \\vert$\n",
    "\n",
    "Assuming $N$ items are spread evenly over all inverted lists, each list $L(h)$ contains roughly $N/L$ items.\n",
    "\n",
    "Search complexity is:\n",
    "$${M \\cdot N \\over L} $$\n",
    "\n",
    "compared to \n",
    "\n",
    "$${M \\cdot N} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Implementation example\n",
    "\n",
    "- Set up the database. \n",
    "- Load some songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = fmp.FingerprintDB()\n",
    "db.add(\"audio/beatles_magical_mystery_tour.wav\")\n",
    "db.add(\"audio/brahms_hungarian_5.wav\")\n",
    "db.add(\"audio/beethoven_5_1_dudamel.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('songs:')\n",
    "print('\\n'.join(db.song_names))\n",
    "print(f'feature rate: {db.ff()}')\n",
    "print(f'song locations: {db.song_locs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in sorted(db.hash_list):\n",
    "    print(f'{h}:', db.hash_list[h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a previously constructed database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "DB_FILEPATH = \"data/fpdb.pickle\"\n",
    "\n",
    "# create the database:\n",
    "# import glob\n",
    "# files = sorted(glob.glob(\"/Users/eran/dev/audio/*.wav\"))\n",
    "# fmp.make_fingerprint_db(files, DB_FILEPATH)\n",
    "    \n",
    "# load the database:\n",
    "db = pickle.load(open(DB_FILEPATH, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats of this database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'num songs: {len(db.song_names)}')\n",
    "print(f'total duration: {db.sample_offset/db.ff()/60:.1f} minutes')\n",
    "\n",
    "list_lengths = np.array([len(db.hash_list[x]) for x in db.hash_list])\n",
    "print(f'num hash values:{len(list_lengths)}')\n",
    "print(f'num items: {np.sum(list_lengths)}')\n",
    "print(f'ave hash list length: {np.mean(list_lengths)} items')\n",
    "\n",
    "plt.bar(np.arange(len(list_lengths)), list_lengths)\n",
    "plt.title('Lengths of hash lists')\n",
    "plt.show();\n",
    "\n",
    "# song names:\n",
    "for s in db.song_names:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run some queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system(\"open -a Audacity\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd = fmp.load_wav(\"audio/query1.wav\")\n",
    "ipd.Audio(snd, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, max_pts = db.query(snd, 3)\n",
    "\n",
    "for r in results:\n",
    "    print(f'name:{r[0]}\\n  score:{r[2]} at:{r[1]:.3f} seconds of song')\n",
    "\n",
    "top = results[0]\n",
    "ipd.Audio(fmp.load_wav(top[0], top[1], top[1] + 10), rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Optimization\n",
    "\n",
    "The current hashing scheme is not that good. \n",
    "- $L=400$\n",
    "- To improve ${M \\cdot N \\over L}$, we must increase $L$.\n",
    "\n",
    "<font color=red>__Whiteboard__</font>: Improving hashing\n",
    "\n",
    "Ideas:\n",
    "- Increase FFT size.\n",
    "  - Robustness would suffer.\n",
    "- Define \"item\" as a pairs of peaks\n",
    "  - anchor point (first peak)\n",
    "  - fanout zone $T = (n_z, k_z)$ to find a number of secondary peaks near anchor\n",
    "  - do this for all peaks\n",
    "<img src=\"images/hash_pairs.png\" width=500>\n",
    "\n",
    "Now, the hash function is:\n",
    "$$h = (k_0, k_1, n_1 - n_0)$$\n",
    "The hash space $\\mathcal{H}$ is much larger:\n",
    "$$ \\vert \\mathcal{H} \\vert = K \\cdot K \\cdot n_z$$\n",
    "\n",
    "The number of \"points\" (or items) has also increased:\n",
    "\n",
    "\n",
    "- $F$ (fanout): average number of pairs formed given target zone $T = (n_z, k_z)$\n",
    "- $N_{pairs}$ (database size) $ = N \\cdot F$  \n",
    "- $M_{pairs}$ (query size) $ = M \\cdot F$\n",
    "\n",
    "But the number of hash lists has increased dramatically:\n",
    "- $L_{pairs} = L \\cdot L \\cdot L$ (approx, assuming $n_z \\simeq K$)\n",
    "\n",
    "So:\n",
    "\n",
    "$$ { M_{pairs} \\cdot N_{pairs} \\over L_{pairs} } = { M \\cdot F \\cdot N \\cdot F\\over L \\cdot L \\cdot L} = { F^2 \\over L^2 } \\cdot {M \\cdot N \\over L}$$\n",
    "\n",
    "If $F=10$ and $L=1000$:\n",
    "- the computational speed improvement is $10,000$\n",
    "\n",
    "- the data storage requirement increase by a factor of $F=10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Matching\n",
    "### Goal\n",
    "\n",
    "Given:\n",
    "- A database of audio recordings \n",
    "- A _short audio fragment_ (the query) \n",
    "\n",
    "Retrieve all excerpts from the recordings that are _musically_ similar to the query.\n",
    "\n",
    "The constellation / fingerprint system will not work very well. It is too specific to the audio characteristics of the recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd1 = fmp.load_wav(\"audio/beethoven_5_1_bernstein.wav\", 19.5, 28)\n",
    "ipd.Audio(snd1, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd2 = fmp.load_wav(\"audio/beethoven_5_1_dudamel.wav\", 0, 7)\n",
    "ipd.Audio(snd2, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec_and_constellation(snd):\n",
    "    spec = fmp.stft_mag(snd, fft_len, hop_size)[0:max_bin,:]\n",
    "    points = fmp.make_constellation(snd, fft_len, hop_size, max_bin)\n",
    "    show_spec_and_points(spec, points)\n",
    "    \n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plot_spec_and_constellation(snd1)\n",
    "plt.subplot(2,1,2)\n",
    "plot_spec_and_constellation(snd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chromagrams\n",
    "Instead, we use chroma vectors, with CENS smoothing / downsampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cens(snd):\n",
    "    fft_len = 4096\n",
    "    cens_filt_len = 11\n",
    "    cens_ds = 3\n",
    "    chroma = fmp.make_chromagram(snd, fs, fft_len, fft_len//2)\n",
    "    return fmp.cens(chroma, cens_filt_len, cens_ds)\n",
    "\n",
    "fmp.plot_two_chromas(make_cens(snd1), make_cens(snd2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "- Query is a short (several seconds) chromagram (Sequence X).\n",
    "- Audio database is a concatenation of many individual chromagrams (Sequence Y - very long).\n",
    "\n",
    "<img src=\"images/matching_x_y.png\" width=600>\n",
    "\n",
    "- Idea 1: Slide X across Y, looking for a good match.\n",
    "- Idea 2: Create a cost matrix between X and Y, and find good looking diagonal paths.\n",
    "\n",
    "<font color=red>__Whiteboard__</font>: Cost Matrix\n",
    "\n",
    "Cost Matrix:\n",
    "$$\\mathbf{C}[n,m] = 1 - \\langle x_n, y_m \\rangle$$\n",
    "\n",
    "\n",
    "Example:\n",
    "- Query is first 21 bars of Beethoven's 5th\n",
    "- Database is entire piece (Dudamel recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fmp.load_wav(\"audio/beeth5_query2.wav\")\n",
    "database = fmp.load_wav(\"audio/beethoven_5_1_dudamel.wav\")\n",
    "ipd.Audio(query, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chromagrams for Query and Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmp.plot_two_chromas(make_cens(query), make_cens(database))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Matrix for Query and Chromagram.\n",
    "\n",
    "Can you spot the diagonal paths? Need to zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 1 - np.dot(make_cens(query).T, make_cens(database))\n",
    "plt.imshow(cost, origin='lower', aspect='auto', cmap='gray');\n",
    "plt.xlabel(\"Database\")\n",
    "plt.ylabel(\"Query\")\n",
    "plt.colorbar();\n",
    "# plt.xlim(0, 500)\n",
    "# plt.xlim(800,1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW for finding paths\n",
    "\n",
    "- Diagonals are not perfectly straight lines (tempo differences)\n",
    "- This motivates using Dynamic Time Warping\n",
    "- But we don't want to align corners\n",
    "- And we want to find (potentially) many paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>__Whiteboard__</font>: Multipath DTW\n",
    "\n",
    "Recall in classic DTW, calculate $\\mathbf{D}$ (accumulated cost matrix) from $\\mathbf{C}$:\n",
    "\n",
    "$$\\mathbf{D}[n,1] = \\sum_{k=1}^n \\mathbf{C}[k,1] \\text{ for } n \\in[1:N] $$\n",
    "$$\\mathbf{D}[1,m] = \\sum_{k=1}^m \\mathbf{C}[1,k] \\text{ for } m \\in[1:M] $$\n",
    "$$\\mathbf{D}[n,m] = \\mathbf{C}[n,m] + \\mathrm{min}\n",
    "\\begin{cases}\n",
    "\\mathbf{D}[n-1,m] \\\\\n",
    "\\mathbf{D}[n,m-1] \\\\\n",
    "\\mathbf{D}[n-1,m-1] \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "For this variant, replace the initialization of the first row of $\\mathbf{D}$ with:\n",
    "$$\\mathbf{D}[1,m] = \\mathbf{C}[1,m]$$\n",
    "\n",
    "This removes any penalty from \"starting in the middle of sequence Y\".\n",
    "\n",
    "Instead of looking at $\\mathbf{D}[N,M]$ for the total accumulated cost of the optimal warping path, examine the entire final row  $\\mathbf{D}[N,m] \\text{ for } m \\in[1:M]$.\n",
    "\n",
    "The optimal path _ends_ at the timestep:\n",
    "$$b^* = \\underset{b \\in[1:M]}{\\operatorname{argmin}}\\mathbf{D}[N,b]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the example above, this is $\\mathbf{D}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, matches = fmp.dtw_match(cost, 3)\n",
    "plt.imshow(D, origin='lower',  aspect='auto', cmap='gray');\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last row of $\\mathbf{D}$ (or the top row in the above plot) is called the __DTW matching function__:\n",
    "\n",
    "$$\\Delta_{\\text{DTW}}[m] = \\mathbf{D}[N,m]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, matches = fmp.dtw_match(cost, 3)\n",
    "top_row = D[-1,:]\n",
    "best = np.argmin(top_row)\n",
    "plt.plot(top_row);\n",
    "plt.plot(best, top_row[best], 'ro')\n",
    "plt.ylabel('cost', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the accumulated cost for ending at each time step. The lowest cost point $b^*$ is the _end_ of the optimal matching subsequence.\n",
    "\n",
    "Following the backtracking matrix leads to $a^*$, the beginning of the optimal matching sequence.\n",
    "\n",
    "Or, for sequence $X[n], n \\in [1:N]$ (the query), the optimal matching subsequence of $Y$ (the database) is $Y[a^*:b^*]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Matches\n",
    "\n",
    "We can find multiple matches as well:\n",
    "- find the lowest cost (argmin).\n",
    "- squash out surrounding area.\n",
    "- repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = fmp.find_top_n_peaks(-top_row, 3, 200)\n",
    "@interact(n=(0,6))\n",
    "def show_n_matches(n=0):\n",
    "    x = top_row.copy()\n",
    "    sq = n // 2\n",
    "    pk = (n-1) // 2 + 1\n",
    "    for i in range(sq):\n",
    "        p = peaks[i]\n",
    "        s = max(p - 100, 0)\n",
    "        e = min(p + 100, len(x) - 1)\n",
    "        x[s:e] = np.max(x)\n",
    "    plt.plot(x)\n",
    "    pks = peaks[:pk]\n",
    "    plt.plot(pks, top_row[pks], 'ro')\n",
    "    plt.ylim(0, 35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of the match is related to the cost. So we can return a google-style ordered list of matches.\n",
    "\n",
    "### Multipiece Database Example\n",
    "\n",
    "Create the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb = fmp.MatchDB()\n",
    "mdb.add(\"audio/beethoven_5_1_bernstein.wav\")\n",
    "mdb.add(\"audio/brahms_hungarian_5.wav\")\n",
    "mdb.add(\"audio/beethoven_5_1_dudamel.wav\")\n",
    "mdb.add(\"audio/beethoven_5_1_morton.wav\")\n",
    "mdb.add(\"audio/beatles_magical_mystery_tour.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fmp.load_wav(\"audio/beeth5_query.wav\")\n",
    "ipd.Audio(query, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, match_fn = mdb.query(query, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A view of the cost function for the whole database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(bounds=False)\n",
    "def show_cost(bounds):\n",
    "    plt.plot(match_fn)\n",
    "    if bounds:\n",
    "        _min, _max = np.min(match_fn), np.max(match_fn)\n",
    "        plt.vlines(mdb.song_locs, _min, _max, 'r')\n",
    "        for i,s in enumerate(mdb.song_names):\n",
    "            txt = s.split('/')[1].split('.')[0]\n",
    "            plt.text(mdb.song_locs[i], _max * .8 + 3*(i%2), txt)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(r=(0,len(results)-1))\n",
    "def play_result(r=0):\n",
    "    r = results[r]\n",
    "    print(f'{r[0]}\\nspan: {r[1]:.1f} to {r[2]:.1f} seconds\\ncost: {r[3]:.2f}')\n",
    "    snd = fmp.load_wav(r[0], r[1], r[2])\n",
    "    return ipd.Audio(snd, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for Lab 8\n",
    "\n",
    "In Lab 8, we will create song databases using music contributed by all students. Find __two songs__ (ideally < 10 minutes each) and convert them to mono 22k WAV file using Audacity. Name them `<artist>_<songname>.wav`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "state": {
    "308ca0cb7e5f4a60b80400c936b686f8": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "4914a264520e41b284509ff29d14e27c": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "4b8b9a3dba2c41d0a8e1aaa31fbca102": {
     "views": [
      {
       "cell_index": 78
      }
     ]
    },
    "8c47e9db89c84a56ae00f0c6448c30ce": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "90d101046d5b49b1ba10e7904c0cb29a": {
     "views": [
      {
       "cell_index": 70
      }
     ]
    },
    "b09022601cf64ee98f3b19a11e09f981": {
     "views": [
      {
       "cell_index": 79
      }
     ]
    },
    "bfb717b3463443c4b97d2e3976c61f5c": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "cdba7379088042cfa3899664e1c2bc34": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
