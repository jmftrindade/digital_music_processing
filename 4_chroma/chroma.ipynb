{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21M.387 Fundamentals of Music Processing\n",
    "## Chromagrams\n",
    "\n",
    "In this lecture: deriving and using chromagrams, starting with the STFT, moving onto pitch-o-grams, and finally to chromagrams, their properties, and enhancement strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from ipywidgets import interact\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import fmplib as fmp\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "fmp.documentation_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "\n",
    "Chapters 3.0 - 3.1 (pp 115 – 130), 7.2.1 (pp 374 – 376)\n",
    "\n",
    "<img src=\"images/book_cover.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "We now move from a _low-level_ to a _mid-level_ feature representation.\n",
    "\n",
    "- low level: close to the raw audio.\n",
    "- mid level: some data reduction, focusing the feature space on a more specific task.\n",
    "\n",
    "We will learn about _chromagrams_, which capture the pitch-content and harmonic content of a signal. Chromagrams are:\n",
    "- insensitive to octave\n",
    "- insensitive to timbre\n",
    "- closely related to how the ear hears pitch.\n",
    "\n",
    "\n",
    "## Spectrograms and Frequency Distribution\n",
    "\n",
    "Chromagrams begin with the Spectrogram of the STFT, $\\lvert \\mathcal{X} [k,m] \\rvert^2$, for $x[n]$.\n",
    "\n",
    "We hear pitch proportional to the logarithm of frequency. But the STFT is linear in frequency.\n",
    "\n",
    "This is an audio sample of a piano playing a chromatic scale, from the lowest to the highest note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fmp.load_wav(\"audio/piano_chromatic.wav\")\n",
    "fs = 22050\n",
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 2048\n",
    "hop_size = win_len // 2\n",
    "\n",
    "spec = fmp.stft_mag(x, win_len, hop_size)\n",
    "\n",
    "plt.figure()\n",
    "fmp.plot_spectrogram(spec, fs=fs)\n",
    "plt.ylim(0,fs/4)\n",
    "plt.title(\"$|\\mathcal{X}|^2$: Spectrogram with N=%d, H=%d\" % (win_len, hop_size), fontsize=15)\n",
    "plt.xlabel(\"n (time steps)\", fontsize=15)\n",
    "plt.ylabel(\"$F_s$\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the frequency locations of the pitch classes on the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_class_name(pc) :\n",
    "    return ('C', 'C#', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B')[pc]\n",
    "\n",
    "def plot_spec_with_pitchclass(spec, fs, pc):\n",
    "    N = 2 * (spec.shape[0] - 1)\n",
    "    pitches = pc + 36 + np.arange(6) * 12\n",
    "    freqs = fmp.pitch_to_freq(pitches)\n",
    "    fmp.plot_spectrogram(spec, fs=fs)\n",
    "    plt.xlabel(\"n (time steps)\")\n",
    "    plt.ylabel(\"$F_s$\")\n",
    "    ytop = fs/4\n",
    "    plt.ylim(0, ytop)\n",
    "    plt.hlines(freqs, 0, spec.shape[1], 'r', linewidth=2)\n",
    "    txt = 'pitch class:' + pitch_class_name(pc)\n",
    "    plt.text(10, ytop-500, txt , fontsize=20, color='yellow')\n",
    "\n",
    "@interact(pc=(0,11))\n",
    "def _pswp(pc = 0):\n",
    "    plt.figure()\n",
    "    plot_spec_with_pitchclass(spec, fs, pc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch-o-grams\n",
    "\n",
    "Our first goal is to convert this Spectrogram into a _log-frequency spectrogram_. Or what I call a pitch-o-gram.\n",
    "\n",
    "How do we do that?\n",
    "\n",
    "We figure which bins in the Spectrogram contribute to a particular pitch!\n",
    "\n",
    "<font color='red'>__Whiteboard__</font>: pitch bounds\n",
    "\n",
    "For example: A4, p=69.  \n",
    "We look $\\pm 0.5$ around that pitch: $[68.5, 69.5]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 69\n",
    "pm = p - 0.5\n",
    "pp = p + 0.5\n",
    "print(f'Lower Bound pitch:{pm:.1f} frequency = {fmp.pitch_to_freq(pm):.2f}')\n",
    "print(f'Center      pitch:{p:.1f} frequency = {fmp.pitch_to_freq(p):.2f}')\n",
    "print(f'Upper Bound pitch:{pp:.1f} frequency = {fmp.pitch_to_freq(pp):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the pitch 69 spans from 427.47Hz to 452.89Hz.\n",
    "\n",
    "Which bins of the Spectrogram does that correspond to?  \n",
    "This depends on $N$ and $F_s$:\n",
    "\n",
    "$$ f = k \\cdot {F_s \\over N} $$\n",
    "\n",
    "Lets try $N=2048$ and $F_s = 22050$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [livecode]\n",
    "N = 2048\n",
    "fs = 22050\n",
    "bins = np.arange(N//2 + 1)\n",
    "freqs = bins * fs / N\n",
    "for k in bins[35:50]:\n",
    "    print(f'k={k}  f={freqs[k]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins $\\{40, 41, 42\\}$ contribute to pitch 69.\n",
    "\n",
    "For $\\lvert X[k] \\lvert^2$ (single column of the Spectrogram), we can formulate this operation of \"picking up the contributions\" from bins $\\{40, 41, 42\\}$ as a dot product of 2 vectors:\n",
    "\n",
    "$$ p_{69} = \\langle C_{69}, \\lvert X[k] \\lvert^2 \\rangle $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "C_{69}(n) = \n",
    "\\begin{cases}\n",
    "1 &\\text{for  } n \\in \\{40, 41, 42\\} \\\\\n",
    "0 &\\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<font color='red'>__Whiteboard__</font>: pitch-picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a table that assigns some set of bins to a particular pitch by repeating the above process for all pitches.\n",
    "\n",
    "Express the Spectrogram $\\lvert \\mathcal{X}[k,m] \\rvert^2$ as the matrix $\\mathbf{X}$.\n",
    "\n",
    "The linear algebra way of thinking about this is to create a transform (conversion) matrix $\\mathbf{C}_{fp}$ that, when multiplied with the spectrogram $\\mathbf{X}$ will produce the pitch-o-gram $\\mathbf{P}$:\n",
    "\n",
    "$$\\mathbf{P} = \\mathbf{C}_{fp} \\cdot \\mathbf{X}$$\n",
    "\n",
    "Assume the following constants:\n",
    "\n",
    "- $M$ is the length of the spectrogram (number of \"hops\")  \n",
    "- $K$ is the number of frequency bins. $K = 1 + N/2$.  \n",
    "- $P$ is the number of midi pitches. $P = 128$.\n",
    "\n",
    "$\\mathbf{X} \\text{ is a } K \\times M$ matrix  \n",
    "$\\mathbf{P} \\text{ is a } P \\times M$ matrix  \n",
    "$\\mathbf{C}_{fp} \\text{ must be a } P \\times K$ matrix  \n",
    "\n",
    "<font color='red'>__Whiteboard__</font>: pitch-o-gram matrix\n",
    "\n",
    "And it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_fp = fmp.spec_to_pitch_mtx(fs, N)\n",
    "plt.imshow(c_fp, origin='lower', aspect='auto', cmap='Greys')\n",
    "plt.xlabel(\"k (frequency bin)\")\n",
    "plt.ylabel(\"midi pitch\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can zoom in on a few pitches. For example: p = 69, p = 70, p = 71:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 2))\n",
    "plt.imshow(c_fp, origin='lower', aspect='auto', cmap='Greys')\n",
    "plt.xlim(32, 50)\n",
    "plt.ylim(68.5, 71.5)\n",
    "plt.xlabel(\"k (frequency bin)\")\n",
    "plt.ylabel(\"midi pitch\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Frequency Problems\n",
    "\n",
    "This works fine for high frequencies. Lots of bins contribute to one note. But we have a problem with low notes.\n",
    "\n",
    "Some notes fall \"in between the gaps\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(c_fp, origin='lower', aspect='auto', cmap='Greys')\n",
    "plt.xlabel(\"k (frequency bin)\")\n",
    "plt.ylabel(\"midi pitch\")\n",
    "plt.ylim(0, 50)\n",
    "plt.xlim(0, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Solution: increase $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(ni = (0, 3))\n",
    "def cfp_n(ni = 0) :\n",
    "    N = (2048, 4096, 8192, 8192*2)[ni]\n",
    "    c_fp = fmp.spec_to_pitch_mtx(fs, N)\n",
    "    plt.figure()\n",
    "    plt.imshow(c_fp, origin='lower', aspect='auto', cmap='Greys')\n",
    "    plt.xlabel(\"k (frequency bin)\")\n",
    "    plt.ylabel(\"midi pitch\")\n",
    "    plt.ylim(0, 60)\n",
    "    plt.xlim(0, 60)\n",
    "    txt = 'N=%d' % N\n",
    "    plt.text(0, 45, txt, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to increase $N$:\n",
    "- zero pad the signal to increase the DFT window without increasing the sampling window\n",
    "- increase the sampling window\n",
    "\n",
    "Let's try the first.\n",
    "\n",
    "Here is a low piano note: C2 (pitch = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd = fmp.load_wav('audio/piano_c1.wav')\n",
    "print('len =', len(snd))\n",
    "ipd.Audio(snd, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with 2048 samples of audio (~93 milliseconds).\n",
    "\n",
    "Use zero padding to increase $N$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_increase_N(x, zpf, pitches) :\n",
    "    # optional zero pad to zpf:\n",
    "    N = len(x)\n",
    "    N *= zpf\n",
    "    x_zp = np.concatenate((x * np.hanning(len(x)), np.zeros(N - len(x))))\n",
    "\n",
    "    plt.figure()\n",
    "    xl = N // 120\n",
    "    mag_ft = abs(np.fft.rfft(x_zp))[:xl]\n",
    "    yl = np.max(mag_ft)\n",
    "    plt.plot(mag_ft, 'bo')\n",
    "    plt.plot(mag_ft)\n",
    "    plt.xlim(0, xl)\n",
    "    plt.title(f'N={N} (x len={len(x)} + zp={N-len(x)})')\n",
    "    plt.xlabel('k', fontsize=15)\n",
    "    plt.ylabel('$|X[k]|$', fontsize=15)\n",
    "    c = 0\n",
    "    for p in pitches:\n",
    "        bins = fmp.bins_of_pitch(p, fs, N)\n",
    "        if len(bins):\n",
    "            b = bins[0]\n",
    "            plt.text(b, yl*.6 + c%2, str(p), fontsize=10)\n",
    "            c += 1\n",
    "            for b in bins:\n",
    "                plt.vlines(b, 0, yl * .6, 'r')\n",
    "    plt.show()\n",
    "\n",
    "# start a bit after the attack:\n",
    "n1 = 10000\n",
    "pitches = (33, 34, 35, 36, 37, 38)\n",
    "\n",
    "# try different zero pad values:\n",
    "@interact(zi = (0,3))\n",
    "def test_zp(zi=0):\n",
    "    N = 2048\n",
    "    x = snd[n1:n1+N] * np.hanning(N)    \n",
    "    test_increase_N(x, 2 ** zi, pitches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So zero-padding helps only in increasing the frequency resolution. But there is still lots of frequency smearing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now incease N by using a longer window. No zero-pad\n",
    "@interact(ni = (0,3))\n",
    "def test_inc_N(ni=0):\n",
    "    N = 2048 * (2 ** ni)\n",
    "    x = snd[n1:n1+N] * np.hanning(N)    \n",
    "    test_increase_N(x, 1, pitches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A larger window helps much more. There is less smearing, but at the cost of lower time resolution.\n",
    "\n",
    "$N = 16384$ will requires a window length of $743$ms with sampling rate ($F_s = 22050$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refinement:\n",
    "\n",
    "Instead of just a brick-wall for distributing frequency bins to a pitch, use a Gaussian or Hann weighting curve.\n",
    "\n",
    "For example: Here is $\\mathbf{C}_{fp}$ with a Hann window centered around a pitch's center frequency, and falling off to zero at ${\\pm 0.5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8192\n",
    "c_fp = fmp.spec_to_pitch_mtx(fs, N, type='hann')\n",
    "plt.figure()\n",
    "plt.imshow(c_fp, origin='lower', aspect='auto', cmap=\"Greys\")\n",
    "plt.xlabel(\"k (frequency bin)\")\n",
    "plt.ylabel(\"midi pitch\")\n",
    "plt.title(\"$\\mathbf{C}_{fp}$ with $N=%d$\" % N)\n",
    "plt.colorbar();\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.stem(c_fp[84,:])\n",
    "plt.xlim(300, 500)\n",
    "plt.title(\"Frequency weights for p=84\", fontsize=15)\n",
    "plt.xlabel(\"k (frequency bin)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also very helpful to \"tune\" $\\mathbf{C}_{fp}$ to the particular pitch used in the recording. For example, some orchestras tune A to something other than 440Hz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have $\\mathbf{C}_{fp}$, let's create the pitch-o-gram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fmp.load_wav(\"audio/piano_chromatic.wav\")\n",
    "fs = 22050\n",
    "N = 4092\n",
    "fft_len = N\n",
    "hop_size = fft_len // 4\n",
    "\n",
    "spec = fmp.stft_mag(x, fft_len, hop_size) ** 2\n",
    "c_fp = fmp.spec_to_pitch_mtx(fs, fft_len, type='hann')\n",
    "\n",
    "pitchogram = np.dot(c_fp, spec)\n",
    "plt.figure()\n",
    "fmp.plot_spectrogram(pitchogram)\n",
    "plt.ylabel('MIDI pitch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pitchogram_with_pitchclass(spec, fs, pc):\n",
    "    N = 2 * (spec.shape[0] - 1)\n",
    "    pitches = pc + 24 + np.arange(7) * 12\n",
    "    fmp.plot_spectrogram(spec)\n",
    "\n",
    "    plt.hlines(pitches, 0, spec.shape[1], 'r', linewidth=2)\n",
    "    txt = 'pitch class:' + pitch_class_name(pc)\n",
    "    \n",
    "    plt.text(0, 120, txt , fontsize=20, color='red')\n",
    "\n",
    "@interact(pc=(0,11))\n",
    "def _ppwp(pc = 0):\n",
    "    plt.figure()\n",
    "    plot_pitchogram_with_pitchclass(pitchogram, fs, pc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chromagrams\n",
    "\n",
    "\n",
    "The next step is to further reduce the feature size by using the principle of octave equivalence. We need to sum all pitches of the pitch-o-gram belonging to the same pitch class.\n",
    "\n",
    "This can be done with another transform / conversion matrix \n",
    "\n",
    "A \"pitch to chroma\" matrix converts a feature space of length 128 pitches to a feature space of length 12 pitch classes.\n",
    "\n",
    "<font color='red'>__Whiteboard__</font>: pitch-to-chroma matrix\n",
    "\n",
    "\n",
    "$\\mathbf{C}_{pc} \\text{ is } 12 \\times 128$ and looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pc = np.tile(np.identity(12), 11)[:, 0:128]\n",
    "plt.figure()\n",
    "plt.imshow(c_pc, origin='lower', cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the the pitch-o-gram matrix $\\mathbf{P}$ to the chromagram $\\mathbf{C}$ with matrix multiplication using the above matrix:\n",
    "\n",
    "$$\\mathbf{C} = \\mathbf{C}_{pc} \\cdot \\mathbf{P} $$\n",
    "\n",
    "The resulting chromagram for the piano chromatic scale is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = np.dot(c_pc, pitchogram)\n",
    "plt.figure()\n",
    "fmp.plot_spectrogram(chromagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can combine the two conversion matrices into one. We have:\n",
    "\n",
    "$$\\mathbf{P} = \\mathbf{C}_{fp} \\cdot \\mathbf{X} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\mathbf{C} = \\mathbf{C}_{pc} \\cdot \\mathbf{P} $$\n",
    "\n",
    "Which means:\n",
    "\n",
    "$$\\mathbf{C} = \\mathbf{C}_{pc} \\cdot \\mathbf{C}_{fp} \\cdot \\mathbf{X} $$\n",
    "\n",
    "Since matrix multiplication is associative, we can define:\n",
    "$$\\mathbf{C}_{fc} = \\mathbf{C}_{pc} \\cdot \\mathbf{C}_{fp}$$\n",
    "\n",
    "which then creates the chromagram in one step:\n",
    "\n",
    "$$\\mathbf{C} = \\mathbf{C}_{fc} \\cdot \\mathbf{X} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_fp = fmp.spec_to_pitch_mtx(fs, N, type='hann')\n",
    "c_fc = np.dot(c_pc, c_fp)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(c_fc, origin='lower', cmap='Greys', aspect='auto');\n",
    "plt.colorbar()\n",
    "plt.xlabel('k (frequency bins)')\n",
    "plt.ylabel('pitch class')\n",
    "plt.title(\"$\\mathbf{C}_{fc}$\", fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chromagram Enhancements\n",
    "\n",
    "\n",
    "The above plots of the piano chromatic scale (Spectrogram, Pitchogram, Chromagram) have been log-scale plots. This is what the chromatic chromagram looks like with linear values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = np.dot(c_fc, spec)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(chromagram, origin='lower', aspect='auto')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did with Spectrogram, we can improve the chromagram by using logarithmic compression.\n",
    "This helps bring out energy that our ears hear, but that otherwise would be under-represented in the data.\n",
    "\n",
    "$\\Gamma_\\gamma(v) = \\log(1+ \\gamma \\cdot v)$\n",
    "\n",
    "- $v$ is the value to compress\n",
    "- $\\gamma$ is the compression factor\n",
    "\n",
    "$\\mathcal{C}_\\gamma =  \\log(1+ \\gamma \\cdot \\mathcal{C})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd1 = fmp.load_wav(\"audio/piano_c4.wav\")\n",
    "snd2 = fmp.load_wav(\"audio/violin_c4.wav\")\n",
    "display(ipd.Audio(snd1, rate=fs, normalize=False))\n",
    "display(ipd.Audio(snd2, rate=fs, normalize=False))\n",
    "\n",
    "fs = 22050\n",
    "fft_len = 8192\n",
    "\n",
    "@interact(gi=(0,4), norm=False)\n",
    "def chroma_variants(gi=0, norm=False):\n",
    "    gamma = (0, .1, 1, 10, 100)[gi]\n",
    "    chroma1 = fmp.make_chromagram(snd1, fs, fft_len, fft_len // 2, norm, gamma)\n",
    "    chroma2 = fmp.make_chromagram(snd2, fs, fft_len, fft_len // 2, norm, gamma)\n",
    "\n",
    "    txt = f'$\\gamma = {gamma:.1f}$ ' + (\"\",\"normalized\")[norm]\n",
    "    plt.figure(figsize = (15, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(chroma1, origin='lower', aspect='auto')\n",
    "    plt.title('piano')\n",
    "    plt.colorbar()\n",
    "    plt.text(0, 12, txt, fontsize=20)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(chroma2, origin='lower', aspect='auto')\n",
    "    plt.title('violin')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We almost always normalize the chromagram as well:\n",
    "\n",
    "Each 12-point column vector is normalized with respect to some norm $\\Vert \\cdot \\Vert$. We most often use the _Euclidean norm_ (also called the $L^2$ norm).\n",
    "\n",
    "For a vector $x$, the Euclidean norm is:\n",
    "\n",
    "$$\\Vert x \\Vert = {\\langle x , x \\rangle}^{1/2}$$\n",
    "\n",
    "Then, each column vector of the chromagram is replaced with:\n",
    "\n",
    "$${x \\over \\Vert x \\Vert}$$\n",
    "\n",
    "This has the effect of making chromagrams invariant to changes in volume. Only the values relative to each other matter.\n",
    "\n",
    "The _direction_ of the chroma vector remains the same.\n",
    "\n",
    "<font color='red'>__Whiteboard__</font>: visualizing chroma vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snd1 = fmp.load_wav(\"audio/beeth5_orch_21bars.wav\")\n",
    "snd2 = fmp.load_wav(\"audio/beeth5_piano_21bars.wav\")\n",
    "fs = 22050\n",
    "fft_len = 4096\n",
    "hop_size = fft_len // 2\n",
    "\n",
    "chroma1 = fmp.make_chromagram(snd1, fs, fft_len, hop_size, True, 8)\n",
    "chroma2 = fmp.make_chromagram(snd2, fs, fft_len, hop_size, True, 8)\n",
    "plt.figure()\n",
    "fmp.plot_two_chromas(chroma1, chroma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ipd.Audio(snd1, rate = fs))\n",
    "display(ipd.Audio(snd2, rate = fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another enhancement strategy is to smooth and downsample the chromagrams.\n",
    "\n",
    "A technique developed by Muller et al is called _CENS_ (Chroma Energy Normalized Statistics). See pages 374-376 in the textbook. It has 5 steps to enhance a standard chormagram:\n",
    "\n",
    "1. Normalize with a Manhattan Norm (also called $L_1$ norm).\n",
    "1. Logarithmic quantization with a noise floor.\n",
    "1. Time Smoothing (param $l$).\n",
    "1. Downsampling (param $d$).\n",
    "1. Normalizing again by Euclidean norm\n",
    "\n",
    "This has several beneficial effects:\n",
    "- It suppresses \"indistinct\" vectors (by using the $L_1$ norm).\n",
    "- It removes noise below a certain level\n",
    "- It creates \"logarithmic-style\" compression\n",
    "- It removes small fluctuations\n",
    "- It reduces the data rate\n",
    "\n",
    "<font color='red'>__Whiteboard__</font>: CENS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(cens = False, win_len = (1, 21, 2), ds=(1,10))\n",
    "def cens_variants(cens, win_len=1, ds=1):\n",
    "    if cens:\n",
    "        chroma1 = fmp.make_chromagram(snd1, fs, fft_len, hop_size)\n",
    "        chroma2 = fmp.make_chromagram(snd2, fs, fft_len, hop_size)\n",
    "        chroma1 = fmp.cens(chroma1, win_len, ds)\n",
    "        chroma2 = fmp.cens(chroma2, win_len, ds)\n",
    "    else:\n",
    "        chroma1 = fmp.make_chromagram(snd1, fs, fft_len, hop_size, True, 8)\n",
    "        chroma2 = fmp.make_chromagram(snd2, fs, fft_len, hop_size, True, 8)\n",
    "        \n",
    "\n",
    "    plt.figure()\n",
    "    fmp.plot_two_chromas(chroma1, chroma2)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "state": {
    "05f9bc19fbf84ded87d9eca7cdbb785c": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "0c04c103a128473e8446268b0534a2b0": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "25d5ec9649674f3c85a23a515db01049": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "6eec2aa114f94bd3ab1a87d5da8563fe": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "af17353c84cb4b11b9d8e03c38de675d": {
     "views": [
      {
       "cell_index": 43
      }
     ]
    },
    "b5d76744c47349dfb4f8275286a59e7c": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bbc852d78ce841f6bad70cb00f856d94": {
     "views": [
      {
       "cell_index": 52
      }
     ]
    },
    "f4c9b0febac04de5ae957ac1eb8d202a": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
